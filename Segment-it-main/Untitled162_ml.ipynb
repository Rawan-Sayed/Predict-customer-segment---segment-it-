{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3676,
   "id": "8e3e5bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install lightgbm\n",
    "#import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3677,
   "id": "414facb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import zero_one_loss\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    " \n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "import xgboost as XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import xgboost as XGB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3678,
   "id": "7a1369f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\\\Users\\Abduallah Hussien\\\\Desktop\\Untitled Folder 1\\\\milestone 2\\\\train.csv\")\n",
    "df_test=pd.read_csv(r'C:\\\\Users\\Abduallah Hussien\\\\Desktop\\Untitled Folder 1\\\\milestone 2\\\\test.csv')\n",
    "allData = [df, df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3679,
   "id": "5b2bf2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10497</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>42</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4228</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>80</td>\n",
       "      <td>No</td>\n",
       "      <td>Executive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10369</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>66</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Artist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10442</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>39</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>8.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>4323</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>79</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Artist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>3776</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>6697</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>73</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Artist</td>\n",
       "      <td>5.0</td>\n",
       "      <td>High</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>3431</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>20</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cat_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>7734</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>58</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10695 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
       "0     10497    Male          Yes   33        No       Engineer   \n",
       "1      5748  Female           No   42       Yes         Doctor   \n",
       "2      4228    Male          Yes   80        No      Executive   \n",
       "3     10369  Female          Yes   66       Yes         Artist   \n",
       "4     10442  Female          Yes   39       Yes     Healthcare   \n",
       "...     ...     ...          ...  ...       ...            ...   \n",
       "3525   4323    Male          Yes   79       Yes         Artist   \n",
       "3526   3776    Male          Yes   40       Yes  Entertainment   \n",
       "3527   6697    Male          Yes   73       Yes         Artist   \n",
       "3528   3431    Male           No   20        No     Healthcare   \n",
       "3529   7734    Male          Yes   58       Yes         Doctor   \n",
       "\n",
       "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0                 0.0        Average          2.0  Cat_6            B  \n",
       "1                 5.0            Low          1.0  Cat_6            B  \n",
       "2                 0.0           High          2.0  Cat_6            A  \n",
       "3                 0.0        Average          3.0  Cat_6            C  \n",
       "4                 8.0           High          2.0  Cat_1            D  \n",
       "...               ...            ...          ...    ...          ...  \n",
       "3525              NaN           High          2.0  Cat_6          NaN  \n",
       "3526              1.0        Average          2.0  Cat_3          NaN  \n",
       "3527              5.0           High          3.0  Cat_6          NaN  \n",
       "3528              NaN            Low          5.0  Cat_3          NaN  \n",
       "3529              1.0           High          2.0  Cat_6          NaN  \n",
       "\n",
       "[10695 rows x 11 columns]"
      ]
     },
     "execution_count": 3679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all=pd.concat([df,df_test])\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3680,
   "id": "241095af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in allData:\n",
    "    i['Family_Size']=i['Family_Size'].fillna(df_all['Family_Size'].mean())\n",
    "    i['Ever_Married']=i['Ever_Married'].fillna(df_all['Ever_Married'].mode()[0])\n",
    "    i['Profession']=i['Profession'].fillna(df_all['Profession'].mode()[0])\n",
    "    i['Graduated']=i['Graduated'].fillna(df_all['Graduated'].mode()[0])\n",
    "    i['Var_1']=i['Var_1'].fillna(df_all['Var_1'].mode()[0])\n",
    "    i['Work_Experience']=i['Work_Experience'].fillna(15)\n",
    "    df.loc[(df['Work_Experience'] ==15) & (df['Ever_Married'] ==\"No\")&(df['Segmentation'] ==\"D\"), 'Work_Experience'] =0\n",
    "    df.loc[(df['Work_Experience'] ==15) & (df['Age'] <30)&(df['Segmentation'] ==\"D\"), 'Work_Experience'] =0\n",
    "    df.loc[(df['Work_Experience'] ==15) & (df['Age'] >63)&(df['Segmentation'] ==\"D\") & (df['Family_Size'] ==1) , 'Work_Experience'] =0\n",
    "    i.loc[(i['Ever_Married'] ==\"No\") &(i['Graduated'] ==\"No\") & (i['Work_Experience'] ==15) , 'Work_Experience'] =0\n",
    "    i.loc[(i['Profession'] ==\"Homemaker\") &(i['Work_Experience'] ==15) , 'Work_Experience'] =9\n",
    "    i.loc[(i['Profession'] ==\"Lawyer\") &(i['Age'] >65) &(i['Graduated'] ==\"No\") &(i['Work_Experience'] ==15), 'Work_Experience'] =0\n",
    "    i.loc[(i['Work_Experience'] ==15) & (i['Profession'] ==\"Marketing\"), 'Work_Experience'] =0\n",
    "    i.loc[(i['Work_Experience'] ==15) & (i['Profession'] ==\"Doctor\")&(i['Age'] >25) & (i['Age'] <40), 'Work_Experience'] =0\n",
    "    i.loc[(i['Gender'] ==\"Female\") &(i['Ever_Married'] ==\"No\")&(i['Age'] >28) &(i['Work_Experience'] ==15), 'Work_Experience'] =0\n",
    "    i.loc[(i['Work_Experience'] ==15), 'Work_Experience'] =1\n",
    "    i['Graduated']=i['Graduated'].map( {\"Yes\": 1, \"No\": 2} ).astype(int)\n",
    "    i['Ever_Married']=i['Ever_Married'].map( {\"Yes\": 1, \"No\": 0} ).astype(int)\n",
    "    i['Spending_Score']=i['Spending_Score'].map( {\"High\": 1, \"Average\": 2,\"Low\":3} ).astype(int)\n",
    "    i['Gender']=i['Gender'].map( {\"Male\": 1, \"Female\": 2} ).astype(int)\n",
    "    i['Var_1']=i['Var_1'].map( {\"Cat_6\": 6, \"Cat_5\": 5,\"Cat_4\":4,\"Cat_3\":3,\"Cat_2\":2,\"Cat_1\":1,\"Cat_7\": 7} ).astype(int)\n",
    "    i['Profession']=i['Profession'].map( {\"Artist\": 1, \"Healthcare\": 2,\"Entertainment\":3,\"Doctor\":4,\"Engineer\":5,\"Lawyer\":6,\"Executive\": 7,\"Marketing\":8,\"Homemaker\":9} ).astype(int)\n",
    "df['Segmentation']=df['Segmentation'].map( {\"A\": 0, \"B\": 1,\"C\":2,\"D\":3} ).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3681,
   "id": "d3cd6754",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3681-9d277064b969>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Profession'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Work_Experience'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Work_Experience'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Spending_Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Spending_Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"High\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Average\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Low\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Family_Size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Family_Size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Var_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cat_6'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5875\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5876\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5877\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5878\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m     ) -> \"BlockManager\":\n\u001b[1;32m--> 631\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     def convert(\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    671\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot convert non-finite values (NA or inf) to integer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "df=pd.get_dummies(df,prefix='Gender',columns=['Gender'],drop_first=True)\n",
    "df['Ever_Married']=df['Ever_Married'].fillna('Yes')\n",
    "df=pd.get_dummies(df,prefix='Married',columns=['Ever_Married'],drop_first=True)\n",
    "df['Graduated']=df['Graduated'].fillna('Yes')\n",
    "df=pd.get_dummies(df,prefix='Graduated',columns=['Graduated'],drop_first=True)\n",
    "df['Profession'].fillna('missing',inplace=True)\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['Profession']=label_encoder.fit_transform(df['Profession'])\n",
    "df.drop('Profession',axis=1,inplace=True)\n",
    "df['Work_Experience'].fillna(df['Work_Experience'].mean(),inplace=True)\n",
    "df['Spending_Score']=df['Spending_Score'].map( {\"High\": 3, \"Average\": 2,\"Low\":1} ).astype('int')\n",
    "df['Family_Size'].fillna(round(df['Family_Size'].mean()),inplace=True)\n",
    "df['Var_1'].fillna('Cat_6',inplace=True)\n",
    "df['Var_1']=label_encoder.fit_transform(df['Var_1'])\n",
    "df['Var_1']=df['Var_1'].astype('int')\n",
    "df['Spending_Score']=df['Spending_Score'].astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104dbf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.get_dummies(df_test,prefix='Gender',columns=['Gender'],drop_first=True)\n",
    "df_test['Ever_Married']=df_test['Ever_Married'].fillna('Yes')\n",
    "df_test=pd.get_dummies(df_test,prefix='Married',columns=['Ever_Married'],drop_first=True)\n",
    "df_test['Graduated']=df_test['Graduated'].fillna('Yes')\n",
    "df_test=pd.get_dummies(df_test,prefix='Graduated',columns=['Graduated'],drop_first=True)\n",
    "df_test['Profession'].fillna('missing',inplace=True)\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df_test['Profession']=label_encoder.fit_transform(df_test['Profession'])\n",
    "df_test.drop('Profession',axis=1,inplace=True)\n",
    "df_test['Work_Experience'].fillna(df_test['Work_Experience'].mean(),inplace=True)\n",
    "df_test['Spending_Score']=df_test['Spending_Score'].map( {\"High\": 3, \"Average\": 2,\"Low\":1} ).astype('int')\n",
    "df_test['Family_Size'].fillna(round(df_test['Family_Size'].mean()),inplace=True)\n",
    "df_test['Var_1'].fillna('Cat_6',inplace=True)\n",
    "df_test['Var_1']=label_encoder.fit_transform(df_test['Var_1'])\n",
    "df_test['Var_1']=df_test['Var_1'].astype('int')\n",
    "df_test['Spending_Score']=df_test['Spending_Score'].astype('int')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e98de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([149, 764, 2729, 3301, 4528, 5980,1810,3560,6072],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age']=np.sqrt(df['Age'])\n",
    "df['Work_Experience']=np.sqrt(df['Work_Experience'])\n",
    "df['Family_Size']=np.sqrt(df['Family_Size'])\n",
    "df_test['Age']=np.sqrt(df_test['Age'])\n",
    "df_test['Work_Experience']=np.sqrt(df_test['Work_Experience'])\n",
    "df_test['Family_Size']=np.sqrt(df_test['Family_Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3298f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['Segmentation']=label_encoder.fit_transform(df['Segmentation'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395823bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inter_Quartile_Range = df['Family_Size'].quantile(0.75) - df['Family_Size'].quantile(0.25)\n",
    "\n",
    "lower_boundary = df['Family_Size'].quantile(0.25) - (Inter_Quartile_Range * 1.5)\n",
    "upper_boundary = df['Family_Size'].quantile(0.75) + (Inter_Quartile_Range * 1.5)\n",
    "df['Family_Size']= np.where(df['Family_Size'] > upper_boundary, upper_boundary,np.where(df['Family_Size'] < lower_boundary, lower_boundary,df['Family_Size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68693c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf2485",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['Segmentation','ID'],axis=1)\n",
    "y=df['Segmentation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab44a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# n_estimators = [100, 300, 500, 800, 1200]\n",
    "# max_depth = [5, 8, 15, 25, 30]\n",
    "# min_samples_split = [2, 5, 10, 15, 100]\n",
    "# min_samples_leaf = [1, 2, 5, 10] \n",
    "# forest= RandomForestClassifier()\n",
    "\n",
    "# hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "#               min_samples_split = min_samples_split, \n",
    "#              min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "# gridF = RandomizedSearchCV(forest, hyperF, cv = 3, verbose = 1, \n",
    "#                       n_jobs = -1)\n",
    "# bestF = gridF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best depth:\",bestF.best_estimator_.get_params()['max_depth'])\n",
    "print(\"Best n_estimators:\",bestF.best_estimator_.get_params()['n_estimators'])\n",
    "print(\"Best min_samples_split:\",bestF.best_estimator_.get_params()['min_samples_split'])\n",
    "print(\"Best min_samples_leaf:\",bestF.best_estimator_.get_params()['min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f9233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "lgb = lgb.LGBMClassifier(subsample=0.4, reg_lambda=0.2, reg_alpha=1.4,\n",
    "               random_state=1, objective='multiclass', max_depth=18,\n",
    "               min_data_in_leaf=55, learning_rate=0.04, colsample_bytree=0.8,\n",
    "               n_estimators=4000, boosting_type='gbdt'\n",
    ")\n",
    "\n",
    "lgb.fit(X_train, y_train,early_stopping_rounds=100,eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        eval_metric='multi_error', verbose=True)\n",
    "\n",
    "\n",
    "# predicting the output on the validation dataset\n",
    "Y_pred_lgb = lgb.predict(X_test)\n",
    "Y_pred2 = lgb.predict(X_train)\n",
    "Y_pred3 = lgb.predict(X_val)\n",
    "\n",
    "# printing the root mean squared error between real value and predicted value\n",
    "print('Accuracy of model on train set: {:.2f}'.format(lgb.score(X_train, y_train)))\n",
    "print('Accuracy of model on test set: {:.2f}'.format(lgb.score(X_val, y_val)))\n",
    "print('mse of model on train set: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, Y_pred2))))\n",
    "print('mse of model on test set: {:.2f}'.format(np.sqrt(mean_squared_error(y_val, Y_pred3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21850ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=df_test.drop(['ID'],axis=1)\n",
    "iD=df_test['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc13449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rf = RandomForestClassifier(n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features='sqrt', max_depth=5, bootstrap=True) \n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predicting the output on the validation dataset\n",
    "Y_pred_rf = rf.predict(X_test)\n",
    "Y_pred2 = rf.predict(X_train)\n",
    "Y_pred3 = rf.predict(X_val)\n",
    "\n",
    "# printing the root mean squared error between real value and predicted value\n",
    "print('Accuracy of model on train set: {:.2f}'.format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of model on test set: {:.2f}'.format(rf.score(X_val, y_val)))\n",
    "print('mse of model on train set: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, Y_pred2))))\n",
    "print('mse of model on test set: {:.2f}'.format(np.sqrt(mean_squared_error(y_val, Y_pred3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'iterations':np.arange(1000,5000,1000), 'learning_rate':np.arange(0,0.1,0.01), 'objective':['Logloss','MultiClass','MultiClassOneVsAll'],\n",
    "#              'max_depth':np.arange(1,10,1),'random_strength':[0,1,2,3,4,5],'random_state':[42,0,1]}\n",
    "# model = CatBoostClassifier()\n",
    "# clf = RandomizedSearchCV(estimator=model, param_distributions=parameters,cv=5,verbose=3)\n",
    "# bm = clf.fit(X_train, y_train)\n",
    "# #sorted(clf.cv_results_)\n",
    "# print(bm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15a5103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing all the model objects with default parameters\n",
    "cat = CatBoostClassifier(random_strength=3, random_state=1, objective='MultiClass',max_depth=2, iterations=4000,learning_rate=0.06, silent=True)\n",
    "# training all the model on the training dataset\n",
    "cat.fit(X_train, y_train)\n",
    "# predicting the output on the validation dataset\n",
    "Y_pred = cat.predict(X_test)\n",
    "Y_pred2 = cat.predict(X_train)\n",
    "Y_pred3 = cat.predict(X_val)\n",
    "\n",
    "# printing the root mean squared error between real value and predicted value\n",
    "print('Accuracy of model on train set: {:.2f}'.format(cat.score(X_train, y_train)))\n",
    "print('Accuracy of model on test set: {:.2f}'.format(cat.score(X_val, y_val)))\n",
    "print('mse of model on train set: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, Y_pred2))))\n",
    "print('mse of model on test set: {:.2f}'.format(np.sqrt(mean_squared_error(y_val, Y_pred3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc445695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params={\"n_estimators\":[67,70,100,120],'reg_lambda':[2,1],'gamma':[0,0.3,0.2,0.1]\n",
    "#        ,'eta':[0.06,0.05,0.04]\n",
    "#         ,\"max_depth\":[3,5],'objective':['binary:logistic']}\n",
    "# reg=XGBClassifier()\n",
    "# clf=RandomizedSearchCV(reg,params,cv=10,n_jobs=-1,verbose=1)\n",
    "# bm=clf.fit(X_train,y_train)\n",
    "# print(bm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34786ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(reg_lambda=1, objective='binary:logistic', n_estimators=100, max_depth=3, gamma=0,eta=0.04) \n",
    "# training all the model on the training dataset\n",
    "xgb.fit(X_train, y_train)\n",
    "# predicting the output on the validation dataset\n",
    "Y_pred_xgb = xgb.predict(X_test)\n",
    "Y_pred2 = xgb.predict(X_train)\n",
    "Y_pred3 = xgb.predict(X_val)\n",
    "\n",
    "# printing the root mean squared error between real value and predicted value\n",
    "print('Accuracy of model on train set: {:.2f}'.format(xgb.score(X_train, y_train)))\n",
    "print('Accuracy of model on test set: {:.2f}'.format(xgb.score(X_val, y_val)))\n",
    "print('mse of model on train set: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, Y_pred2))))\n",
    "print('mse of model on test set: {:.2f}'.format(np.sqrt(mean_squared_error(y_val, Y_pred3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c94ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoostClassifier(n_estimators=3,learning_rate=1, random_state=42)\n",
    "# training all the model on the training dataset\n",
    "ada.fit(X_train, y_train)\n",
    "# predicting the output on the validation dataset\n",
    "Y_pred = ada.predict(X_test)\n",
    "Y_pred2 = ada.predict(X_train)\n",
    "Y_pred3 = ada.predict(X_val)\n",
    "\n",
    "# printing the root mean squared error between real value and predicted value\n",
    "print('Accuracy of model on train set: {:.2f}'.format(ada.score(X_train, y_train)))\n",
    "print('Accuracy of model on test set: {:.2f}'.format(ada.score(X_val, y_val)))\n",
    "print('mse of model on train set: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, Y_pred2))))\n",
    "print('mse of model on test set: {:.2f}'.format(np.sqrt(mean_squared_error(y_val, Y_pred3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb75914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#     \"loss\":[\"deviance\"],\n",
    "#     \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "#     \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "#     \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "#     \"max_depth\":[3,5,8],\n",
    "#     \"max_features\":[\"log2\",\"sqrt\"],\n",
    "#     \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "#     \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "#     \"n_estimators\":[10]\n",
    "#     }\n",
    "\n",
    "# clf = RandomizedSearchCV(GradientBoostingClassifier(), parameters, cv=10, n_jobs=-1)\n",
    "# bm = clf.fit(X_train, y_train)\n",
    "# #sorted(clf.cv_results_)\n",
    "# print(bm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8adaf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb=GradientBoostingClassifier(subsample=0.9,n_estimators=10,min_samples_split=0.17272727272727273,min_samples_leaf=0.2090909090909091,\n",
    "                             max_features='log2',max_depth=3,loss='deviance',learning_rate=0.15,criterion='friedman_mse')\n",
    "# training all the model on the training dataset\n",
    "gb.fit(X_train, y_train)\n",
    "# predicting the output on the validation dataset\n",
    "Y_pred = gb.predict(X_test)\n",
    "Y_pred2 = gb.predict(X_train)\n",
    "Y_pred3 = gb.predict(X_val)\n",
    "\n",
    "# printing the root mean squared error between real value and predicted value\n",
    "print('Accuracy of model on train set: {:.2f}'.format(gb.score(X_train, y_train)))\n",
    "print('Accuracy of model on test set: {:.2f}'.format(gb.score(X_val, y_val)))\n",
    "print('mse of model on train set: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, Y_pred2))))\n",
    "print('mse of model on test set: {:.2f}'.format(np.sqrt(mean_squared_error(y_val, Y_pred3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(Y_pred_lgb)\n",
    "data = pd.concat([iD,pred],axis = 1)\n",
    "data.columns = ['ID','Segmentation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf80e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Segmentation'] = data['Segmentation'].map( {0: \"A\",  1: \"B\",2:\"C\",3:\"D\"} ).astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Segmentation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv (r\"C:\\Users\\Abduallah Hussien\\Desktop\\Untitled Folder 1\\milestone 2\\submission_lgb.csv\", index = False, header=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbffab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Segmentation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb055c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"submission.csv\",na_values=' ')\n",
    "#df2 = pd.read_csv(\"0.47.csv\",na_values=' ')\n",
    "#x=df['Segmentation']\n",
    "#x2=df2['Segmentation']\n",
    "#x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4bce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('mse of two models gbr: {:.2f}'.format(np.sqrt(mean_squared_error(x2, x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66d5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
